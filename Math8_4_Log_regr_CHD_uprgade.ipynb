{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 6 модуле мы обучали логистическую регрессию для классификации людей в группу риска ишемической болезни сердца в 10-летней перспрективе по датасету framingham.csv.\n",
    "\n",
    "Если вы помните, модель получилась плохая: несмотря на довольно большую долю верно классифицированных пациентов (около 85%), она очень плохо определяла пациентов группы риска. Чувствительность была нулевая или почти нулевая, а ошибка 2 рода (ложно-отрицательные результаты среди пациентов группы риска) большая.\n",
    "\n",
    "Для медицинского теста это плохо, так как врач пропустит много пациентов с высоким риском заболеть.\n",
    "\n",
    "Проблема заключается вот в чем: в обучающей выборке здоровых пациентов намного больше, чем больных. В этом случае классификатору \"выгодно\" обучиться так, чтобы хорошо определять бОльший класс, так как он тогда чаще будет угадывать.\n",
    "\n",
    "Попробуем улучшить работу классификатора двумя способами: настроив веса в логистической регрессии и сделав undersampling здоровых пациентов в обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем датасет и избавимся от нулевых строк\n",
    "df = pd.read_csv('framingham.csv')\n",
    "df.dropna(axis=0,inplace=True) #избавляемся от строчек с пропущенными значениями\n",
    "\n",
    "# разбиваем датафрейм на две части, dfx - параметры, dfy - целевая переменная. \n",
    "dfx = df.drop('TenYearCHD', axis = 1)\n",
    "dfy = df[['TenYearCHD']] \n",
    "\n",
    "# разбиваем датасет на train и test выборку в соотношениии 80% train / 20% test случайным образом\n",
    "# фиксируем random_state\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfx, dfy, test_size=0.2, random_state=17) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Способ\n",
    "\n",
    "Его идея заключается в том, что мы добавим на этапе обучения бОльший штраф за ошибки для более редкого класса, тем самым увеличивая чувствительность классификатора к этому классу. \n",
    "\n",
    "Среди параметров LogisticRegression есть class_weight. Он может иметь 3 состояния:\n",
    "\n",
    "1. class_weight=None означает, что мы обучаем регрессию как обычно, без доп. настроек. Так мы делали в практике 6 модуля \n",
    "2. class_weight='balanced' задает веса обратно пропорционально количеству элементов в каждом классе. Например, если в выборке будет 1000 здоровых пациентов и 100 больных, то веса будут относиться как 1:10. В описании параметров на https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression есть формула, по которой считаются коэффициенты.\n",
    "3. class_weight=dict - можно задать веса самостоятельно с формате словаря."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала давайте попробуем, как работает логистическая регрессия с весами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LogisticRegression(solver='liblinear', class_weight='balanced') \n",
    "# обучаем\n",
    "model = lm.fit(X_train, y_train.values.ravel()) \n",
    "# сделаем prediction классов на всей тестовой выборке\n",
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[410, 209],\n",
       "       [ 35,  78]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# строим confusion matrix - таблицу правильных и неправильных предсказаний\n",
    "# можно увидеть, что она ведет себя намного лучше, чем для модели без весов!\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, мы сущесвтенно улучшили чувствительность классификатора.\n",
    "\n",
    "Давайте посмотрим на метрики качества:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6666666666666666\n",
      "Sensitivity:  0.6902654867256637\n",
      "Specificity:  0.6623586429725363\n",
      "Pricision:  0.27177700348432055\n",
      "Type I error rate:  0.3376413570274637\n",
      "Type II error rate:  0.30973451327433627\n"
     ]
    }
   ],
   "source": [
    "TN = cnf_matrix[0,0] # True Negative\n",
    "TP = cnf_matrix[1,1] # True Positive\n",
    "FN = cnf_matrix[1,0] # False Negative\n",
    "FP = cnf_matrix[0,1] # False Positive\n",
    "    \n",
    "Ac = lm.score(X_test, y_test)\n",
    "Sens = TP/(TP+FN) \n",
    "Sp = TN/(TN+FP)\n",
    "P = TP/(TP+FP)\n",
    "typeI = FP/(FP+TN)\n",
    "typeII = FN/(FN+TP)\n",
    "    \n",
    "print('Accuracy: ', Ac)\n",
    "print('Sensitivity: ', Sens)\n",
    "print('Specificity: ', Sp)\n",
    "print('Pricision: ', P)\n",
    "print('Type I error rate: ', typeI)\n",
    "print('Type II error rate: ', typeII)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy модели стала меньше, чем в простом случае, но зато ошибка второго рода тоже уменьшилась, что для нас в данном случае важнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтобы не делать 100500 копипастов, создадим функцию print_logit_scores\n",
    "# которая будет обучать регрессию заданным способом и выводить разные метрики качества\n",
    "\n",
    "def print_logit_scores(data_train, target_train, data_test, target_test, model_type, weights):\n",
    "    \n",
    "    # data_train, target_train, data_test, target_test - это обучающие и тестовые данные\n",
    "    # model_type задает один из 3 типов обучения: 'n' - None, 'b' - balanced, 'w' - заданные пользователем веса\n",
    "    # w - вектор весов. Используется только для model_type = 'w'\n",
    "    \n",
    "    if (model_type == 'n'): # обучаем с равными весами\n",
    "        lm = linear_model.LogisticRegression(solver='liblinear', class_weight=None)    \n",
    "    elif (model_type == 'b'): # балансируем веса, как предлагают разработчики sklearn\n",
    "        lm = linear_model.LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "    elif (model_type == 'w'): # балансируем веса самостоятельно\n",
    "        lm = linear_model.LogisticRegression(solver='liblinear', class_weight={0:weights[0], 1:weights[1]})\n",
    "    elif (model_type == 'nbc'):\n",
    "        lm = GaussianNB()\n",
    "\n",
    "    # обучаем\n",
    "    model = lm.fit(data_train, target_train.values.ravel()) \n",
    "\n",
    "    # сделаем prediction классов на всей тестовой выборке\n",
    "    target_pred = lm.predict(data_test)\n",
    "\n",
    "    # строим confusion matrix - таблицу правильных и неправильных предсказаний\n",
    "    cnf_matrix = metrics.confusion_matrix(target_test, target_pred)\n",
    "\n",
    "    TN = cnf_matrix[0,0] # True Negative\n",
    "    TP = cnf_matrix[1,1] # True Positive\n",
    "    FN = cnf_matrix[1,0] # False Negative\n",
    "    FP = cnf_matrix[0,1] # False Positive\n",
    "    \n",
    "    Ac = lm.score(data_test, target_test)\n",
    "    Sens = TP/(TP+FN) \n",
    "    Sp = TN/(TN+FP)\n",
    "    P = TP/(TP+FP)\n",
    "    typeI = FP/(FP+TN)\n",
    "    typeII = FN/(FN+TP)\n",
    "    \n",
    "    print('Accuracy: ', Ac)\n",
    "    print('Sensitivity: ', Sens)\n",
    "    print('Specificity: ', Sp)\n",
    "    print('Precision: ', P)\n",
    "    print('Type I error rate: ', typeI)\n",
    "    print('Type II error rate: ', typeII)\n",
    "    \n",
    "    return [Ac,Sens,Sp,P,typeI,typeII] # возвращаем список метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "интуитивно хочется поделить веса обратно пропорционально количеству элементов в классе, оставив сумму 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15174299, 0.84825701])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share = y_train['TenYearCHD'].value_counts()\n",
    "w0 = share[1]/(share[0]+share[1])\n",
    "w = np.array([w0,1-w0])\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "разработчики sklearn предлагают балансировать веса по другому правилу. При этом они тоже будут обратно пропорциональны количествую элементов, но сумма будет уже не 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.589444  , 3.29504505])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train['TenYearCHD']) # считает количество вхождений 0 и 1 в y_train['TenYearCHD']\n",
    "w_b = y_train.shape[0]/ (2*np.bincount(y_train['TenYearCHD']))\n",
    "w_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "отношение интуитивных весов:  0.17888799355358584\n",
      "отношение balanced весов:  0.17888799355358584\n"
     ]
    }
   ],
   "source": [
    "# Давайте убедимся, что отношения весов действительно одинаковые\n",
    "# При этом бОльший по размеру класс (нулевой, то есть здоровые пациенты) имеет мЕньший вес\n",
    "print('отношение интуитивных весов: ', w[0]/w[1])\n",
    "print('отношение balanced весов: ', w_b[0]/w_b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ручная балансировка по правилу balanced\n",
      "Accuracy:  0.6666666666666666\n",
      "Sensitivity:  0.6902654867256637\n",
      "Specificity:  0.6623586429725363\n",
      "Precision:  0.27177700348432055\n",
      "Type I error rate:  0.3376413570274637\n",
      "Type II error rate:  0.30973451327433627\n",
      "\n",
      "\n",
      "встроенная балансировка по правилу balanced\n",
      "Accuracy:  0.6666666666666666\n",
      "Sensitivity:  0.6902654867256637\n",
      "Specificity:  0.6623586429725363\n",
      "Precision:  0.27177700348432055\n",
      "Type I error rate:  0.3376413570274637\n",
      "Type II error rate:  0.30973451327433627\n",
      "\n",
      "\n",
      "без балансировки весов\n",
      "Accuracy:  0.855191256830601\n",
      "Sensitivity:  0.07964601769911504\n",
      "Specificity:  0.9967689822294022\n",
      "Precision:  0.8181818181818182\n",
      "Type I error rate:  0.0032310177705977385\n",
      "Type II error rate:  0.9203539823008849\n"
     ]
    }
   ],
   "source": [
    "# сравним \n",
    "print('ручная балансировка по правилу balanced')\n",
    "m1 = print_logit_scores(X_train, y_train, X_test, y_test, 'w', w_b) # ручная балансировка по правилу balanced\n",
    "print('\\n')\n",
    "print ('встроенная балансировка по правилу balanced')\n",
    "m2 = print_logit_scores(X_train, y_train, X_test, y_test, 'b', w) # встроенная балансировка по правилу balanced\n",
    "print('\\n')\n",
    "print ('без балансировки весов')\n",
    "m3 = print_logit_scores(X_train, y_train, X_test, y_test, 'n', w) # без балансировки весов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Способ\n",
    "\n",
    "Его идея заключается в том, чтобы уравнять доли \"здоровых\" и \"больных\" в обучающей выборке.\n",
    "\n",
    "Каким образом?\n",
    "\n",
    "Очень просто: из всех \"здоровых\" пациентов в обучающей выборке сделам подвыборку того же размера, сколько у нас \"больных\". Например, если в обучающей выборке 1000 \"здоровых\" и 100 \"больных\", то мы из этой 1000 случайным образом выберем 100. Это называется undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нам понадобится новая библиотека imblearn\n",
    "# в моей версии Anaconda (2019.03) она не предустановлена\n",
    "# возможно, вам тоже нужно установить ее самостоятельно\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# освежите в памяти, что показывает share и что значит share[1]\n",
    "# параметр ratio в RandomUnderSampler задается словарем: \n",
    "# 1: - желаемое количество объектов класса 1\n",
    "# 0: - желаемое количество объектов класса 0\n",
    "\n",
    "# задаем параметры выборки:\n",
    "sampler = RandomUnderSampler(sampling_strategy={1: share[1], 0: share[1]})\n",
    "\n",
    "# сам unpersampling выполняется здесь:\n",
    "X_train_under_np, y_train_under_np = sampler.fit_sample(X_train, y_train)\n",
    "\n",
    "# преобразуем в DataFrame, чтобы скормить логистической регрессии\n",
    "X_train_under = pd.DataFrame(X_train_under_np)\n",
    "y_train_under = pd.DataFrame(y_train_under_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.657103825136612\n",
      "Sensitivity:  0.7256637168141593\n",
      "Specificity:  0.6445880452342488\n",
      "Precision:  0.271523178807947\n",
      "Type I error rate:  0.3554119547657512\n",
      "Type II error rate:  0.2743362831858407\n"
     ]
    }
   ],
   "source": [
    "# вычисляем качество модели с undersampling\n",
    "# как вы думаете, почему в качестве model_type здесь можно взять 'n'?\n",
    "m_u = print_logit_scores(X_train_under, y_train_under, X_test, y_test, 'n', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6666666666666666\n",
      "Sensitivity:  0.6902654867256637\n",
      "Specificity:  0.6623586429725363\n",
      "Precision:  0.27177700348432055\n",
      "Type I error rate:  0.3376413570274637\n",
      "Type II error rate:  0.30973451327433627\n"
     ]
    }
   ],
   "source": [
    "# сравните результаты со встроенной балансировкой на всей обучающей выборке\n",
    "# как вы думаете, какой есть существенный недостаток у undersampling по сравнению с балансировкой весов?\n",
    "m2 = print_logit_scores(X_train, y_train, X_test, y_test, 'b', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_train = pd.read_csv('Admission_train.csv')\n",
    "admission_test = pd.read_csv('Admission_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>318</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>286</td>\n",
       "      <td>287</td>\n",
       "      <td>336</td>\n",
       "      <td>118</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>371</td>\n",
       "      <td>372</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203</td>\n",
       "      <td>204</td>\n",
       "      <td>334</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>398</td>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Serial No.  GRE Score  TOEFL Score  University Rating  SOP  \\\n",
       "0          68          69        318          109                  3  3.5   \n",
       "1         286         287        336          118                  5  4.5   \n",
       "2         371         372        324          110                  3  3.5   \n",
       "3         203         204        334          120                  5  4.0   \n",
       "4         398         399        312          103                  3  3.5   \n",
       "\n",
       "   LOR   CGPA  Research  Chance of Admit   \n",
       "0   4.0  9.22         1              0.68  \n",
       "1   4.0  9.19         1              0.92  \n",
       "2   3.0  9.22         1              0.89  \n",
       "3   5.0  9.87         1              0.97  \n",
       "4   4.0  8.78         0              0.67  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Serial No.', 'GRE Score', 'TOEFL Score',\n",
       "       'University Rating', 'SOP', 'LOR ', 'CGPA', 'Research',\n",
       "       'Chance of Admit '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_train['Chance of Admit '] = admission_train['Chance of Admit '].apply(lambda x: 1 if x> 0.5 else 0)\n",
    "admission_test['Chance of Admit '] = admission_test['Chance of Admit '].apply(lambda x: 1 if x> 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>318</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>286</td>\n",
       "      <td>287</td>\n",
       "      <td>336</td>\n",
       "      <td>118</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>371</td>\n",
       "      <td>372</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203</td>\n",
       "      <td>204</td>\n",
       "      <td>334</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>398</td>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Serial No.  GRE Score  TOEFL Score  University Rating  SOP  \\\n",
       "0          68          69        318          109                  3  3.5   \n",
       "1         286         287        336          118                  5  4.5   \n",
       "2         371         372        324          110                  3  3.5   \n",
       "3         203         204        334          120                  5  4.0   \n",
       "4         398         399        312          103                  3  3.5   \n",
       "\n",
       "   LOR   CGPA  Research  Chance of Admit   \n",
       "0   4.0  9.22         1                 1  \n",
       "1   4.0  9.19         1                 1  \n",
       "2   3.0  9.22         1                 1  \n",
       "3   5.0  9.87         1                 1  \n",
       "4   4.0  8.78         0                 1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>324</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>267</td>\n",
       "      <td>268</td>\n",
       "      <td>314</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>457</td>\n",
       "      <td>458</td>\n",
       "      <td>295</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>263</td>\n",
       "      <td>264</td>\n",
       "      <td>324</td>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159</td>\n",
       "      <td>160</td>\n",
       "      <td>297</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Serial No.  GRE Score  TOEFL Score  University Rating  SOP  \\\n",
       "0         190         191        324          111                  5  4.5   \n",
       "1         267         268        314          107                  3  3.0   \n",
       "2         457         458        295           99                  1  2.0   \n",
       "3         263         264        324          111                  3  2.5   \n",
       "4         159         160        297          100                  1  1.5   \n",
       "\n",
       "   LOR   CGPA  Research  Chance of Admit   \n",
       "0   4.0  9.16         1                 1  \n",
       "1   3.5  8.17         1                 1  \n",
       "2   1.5  7.57         0                 0  \n",
       "3   1.5  8.79         1                 1  \n",
       "4   2.0  7.90         0                 1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admission_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_test.drop(['Unnamed: 0', 'Serial No.'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_train.drop(['Unnamed: 0', 'Serial No.'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = admission_train.drop(['Chance of Admit '], axis=1)\n",
    "y_train = admission_train['Chance of Admit ']\n",
    "X_test = admission_test.drop(['Chance of Admit '], axis=1)\n",
    "y_test = admission_test['Chance of Admit ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.91\n",
      "Sensitivity:  0.967032967032967\n",
      "Specificity:  0.3333333333333333\n",
      "Precision:  0.9361702127659575\n",
      "Type I error rate:  0.6666666666666666\n",
      "Type II error rate:  0.03296703296703297\n"
     ]
    }
   ],
   "source": [
    "m_u = print_logit_scores(X_train, y_train, X_test, y_test, 'n', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.78\n",
      "Sensitivity:  0.7692307692307693\n",
      "Specificity:  0.8888888888888888\n",
      "Precision:  0.9859154929577465\n",
      "Type I error rate:  0.1111111111111111\n",
      "Type II error rate:  0.23076923076923078\n"
     ]
    }
   ],
   "source": [
    "m_b = print_logit_scores(X_train, y_train, X_test, y_test, 'b', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.88\n",
      "Sensitivity:  0.8791208791208791\n",
      "Specificity:  0.8888888888888888\n",
      "Precision:  0.9876543209876543\n",
      "Type I error rate:  0.1111111111111111\n",
      "Type II error rate:  0.12087912087912088\n"
     ]
    }
   ],
   "source": [
    "m_nbc = print_logit_scores(X_train, y_train, X_test, y_test, 'nbc', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
